{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu111 True\n",
      "gcc (Gentoo 10.3.1_p20211126 p0) 10.3.1 20211126\n",
      "Copyright (C) 2020 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyyaml==5.1\n",
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "741d8a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.447170048\n",
      "23.368564736\n",
      "21.921205248\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_properties(0).total_memory/1e9)\n",
    "print(torch.cuda.memory_reserved(0)/1e9)\n",
    "print(torch.cuda.memory_allocated(0)/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import glob\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import Image\n",
    "import time\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from get_iou import get_max_iou, get_iou, get_overlap\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric_tablebank import metric_table_bank_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/data/rali5/Tmp/yockelle/TableBank/TableBank/Detection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_data():\n",
    "    latex = pickle.load( open(path_data + \"annotations/COCO_tablebank_latex_val.pickle\", \"rb\" ) )\n",
    "    word = pickle.load( open(path_data + \"annotations/COCO_tablebank_word_val.pickle\", \"rb\" ) )\n",
    "    return latex + word\n",
    "    \n",
    "# TRAINING DATA\n",
    "def get_train_data_latex():\n",
    "    latex = pickle.load( open(path_data + \"annotations/COCO_tablebank_latex_train.pickle\", \"rb\" ) )\n",
    "    return latex\n",
    "\n",
    "def get_train_data_word():\n",
    "    word = pickle.load( open(path_data + \"annotations/COCO_tablebank_word_train.pickle\", \"rb\" ) )\n",
    "    return word\n",
    "\n",
    "def get_train_data_both():\n",
    "    latex = get_train_data_latex()\n",
    "    word = get_train_data_word()\n",
    "    total_train = latex + word\n",
    "    random.shuffle(total_train)\n",
    "    return total_train\n",
    "\n",
    "def get_train_data_latex_pln():\n",
    "    latex = get_train_data_latex()\n",
    "    pln = get_train_data_publaynet()\n",
    "    total_train = latex + pln\n",
    "    random.shuffle(total_train)\n",
    "    return total_train\n",
    "\n",
    "def get_train_data_word_pln():\n",
    "    word = get_train_data_word()\n",
    "    pln = get_train_data_publaynet()\n",
    "    total_train = word + pln\n",
    "    random.shuffle(total_train)\n",
    "    return total_train\n",
    "\n",
    "def get_train_data_pln_latex_word():\n",
    "    latex = get_train_data_latex()\n",
    "    word = get_train_data_word()\n",
    "    publaynet = get_train_data_publaynet()\n",
    "    total_train = latex + word + publaynet\n",
    "    random.shuffle(total_train)\n",
    "    return total_train\n",
    "\n",
    "# TEST DATA\n",
    "def get_test_data_latex():\n",
    "    latex = pickle.load( open(path_data + \"annotations/COCO_tablebank_latex_test.pkl\", \"rb\" ) )\n",
    "    return latex\n",
    "\n",
    "def get_test_data_word():\n",
    "    word = pickle.load( open(path_data + \"annotations/COCO_tablebank_word_test.pkl\", \"rb\" ) )\n",
    "    return word\n",
    "\n",
    "def get_test_data_both():\n",
    "    latex = get_test_data_latex()\n",
    "    word = get_test_data_word()\n",
    "    total_test = latex + word\n",
    "    random.shuffle(total_test)\n",
    "    return total_test\n",
    "\n",
    "def get_test_data_publaynet():\n",
    "    test_publaynet = pickle.load( open(\"../PubLayNet/COCO_test_set_table_only.pkl\", \"rb\" ) )\n",
    "    for image in test_publaynet:\n",
    "        annotation_array = []\n",
    "        for annot in image[\"annotations\"]:\n",
    "            annot[\"category_id\"] = 0\n",
    "            annotation_array.append(annot)\n",
    "        image['categories'] = [{'supercategory': '', 'id': 0, 'name': 'table'}]\n",
    "        image[\"annotations\"] = annotation_array\n",
    "        image[\"file_name\"] = \"/data/rali5/Tmp/yockelle/PubLayNet/\" + image[\"file_name\"]\n",
    "    return test_publaynet\n",
    "\n",
    "def get_train_data_publaynet():\n",
    "    train_publaynet = pickle.load( open(\"../PubLayNet/COCO_train_set_table_only.pkl\", \"rb\" ) )\n",
    "    for image in train_publaynet:\n",
    "        annotation_array = []\n",
    "        for annot in image[\"annotations\"]:\n",
    "            annot[\"category_id\"] = 0\n",
    "            annotation_array.append(annot)\n",
    "        image['categories'] = [{'supercategory': '', 'id': 0, 'name': 'table'}]\n",
    "        image[\"annotations\"] = annotation_array\n",
    "        image[\"file_name\"] = \"/data/rali5/Tmp/yockelle/PubLayNet/\" + image[\"file_name\"]\n",
    "    return train_publaynet\n",
    "\n",
    "\n",
    "def get_train_data_pln_and_empty():\n",
    "    no_table = pickle.load( open(\"../PubLayNet/COCO_no_table_examples.pkl\", \"rb\" ) )\n",
    "    for image in no_table:\n",
    "        image['categories'] = [{'supercategory': '', 'id': 0, 'name': 'table'}]\n",
    "        image[\"annotations\"] = []\n",
    "        image[\"file_name\"] = \"/data/rali5/Tmp/yockelle/PubLayNet/\" + image[\"file_name\"]\n",
    "\n",
    "    train = get_train_data_publaynet()\n",
    "    total_test = no_table + train\n",
    "    random.shuffle(total_test)\n",
    "\n",
    "    return total_test\n",
    "\n",
    "\n",
    "def get_train_data_and_word_pln_empty():\n",
    "\n",
    "    word = get_train_data_word()\n",
    "\n",
    "    no_table = pickle.load( open(\"../PubLayNet/COCO_no_table_examples.pkl\", \"rb\" ) )\n",
    "    for image in no_table:\n",
    "        image['categories'] = [{'supercategory': '', 'id': 0, 'name': 'table'}]\n",
    "        image[\"annotations\"] = []\n",
    "        image[\"file_name\"] = \"/data/rali5/Tmp/yockelle/PubLayNet/\" + image[\"file_name\"]\n",
    "\n",
    "    train = get_train_data_publaynet()\n",
    "    total_test = no_table + train + word\n",
    "    random.shuffle(total_test)\n",
    "\n",
    "    return total_test\n",
    "\n",
    "def get_train_data_and_latex_pln_empty():\n",
    "\n",
    "    latex = get_train_data_latex()\n",
    "\n",
    "    no_table = pickle.load( open(\"../PubLayNet/COCO_no_table_examples.pkl\", \"rb\" ) )\n",
    "    for image in no_table:\n",
    "        image['categories'] = [{'supercategory': '', 'id': 0, 'name': 'table'}]\n",
    "        image[\"annotations\"] = []\n",
    "        image[\"file_name\"] = \"/data/rali5/Tmp/yockelle/PubLayNet/\" + image[\"file_name\"]\n",
    "\n",
    "    train = get_train_data_publaynet()\n",
    "    total_test = no_table + train + latex\n",
    "    random.shuffle(total_test)\n",
    "\n",
    "    return total_test\n",
    "\n",
    "def get_train_data_word_and_latex_pln_empty():\n",
    "\n",
    "    latex = get_train_data_both()\n",
    "\n",
    "    no_table = pickle.load( open(\"../PubLayNet/COCO_no_table_examples.pkl\", \"rb\" ) )\n",
    "    for image in no_table:\n",
    "        image['categories'] = [{'supercategory': '', 'id': 0, 'name': 'table'}]\n",
    "        image[\"annotations\"] = []\n",
    "        image[\"file_name\"] = \"/data/rali5/Tmp/yockelle/PubLayNet/\" + image[\"file_name\"]\n",
    "\n",
    "    train = get_train_data_publaynet()\n",
    "    total_test = no_table + train + latex\n",
    "    random.shuffle(total_test)\n",
    "\n",
    "    return total_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_name = \"my_dataset_train\"\n",
    "valid_set_name = \"my_dataset_valid\"\n",
    "test_set_name = \"my_dataset_test\"\n",
    "\n",
    "# Train set\n",
    "DatasetCatalog.register(train_set_name, get_train_data_latex)\n",
    "MetadataCatalog.get(train_set_name).set(thing_classes=[\"table\"])\n",
    "text_metadata_train = MetadataCatalog.get(train_set_name)\n",
    "\n",
    "# Validation set\n",
    "DatasetCatalog.register(valid_set_name, get_valid_data)\n",
    "MetadataCatalog.get(valid_set_name).set(thing_classes=[\"table\"])\n",
    "text_metadata_valid = MetadataCatalog.get(valid_set_name)\n",
    "\n",
    "# Test set\n",
    "DatasetCatalog.register(test_set_name, get_test_data_both)\n",
    "MetadataCatalog.get(test_set_name).set(thing_classes=[\"table\"])\n",
    "text_metadata_test = MetadataCatalog.get(test_set_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "\n",
    "    if output_folder is None:\n",
    "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "        output_folder = \"coco_eval\"\n",
    "\n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/22 11:07:44 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (23): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (24): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (25): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (26): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (27): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (28): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (29): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (30): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (31): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (32): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (33): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (34): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (35): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/22 11:07:46 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 187199 images left.\n",
      "\u001b[32m[01/22 11:07:50 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   table    | 237431       |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[01/22 11:07:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/22 11:07:50 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/22 11:07:50 d2.data.common]: \u001b[0mSerializing 187199 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/22 11:07:50 d2.data.common]: \u001b[0mSerialized dataset takes 79.97 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/22 11:07:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/yockelle/.local/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/u/yockelle/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[5m\u001b[31mERROR\u001b[0m \u001b[32m[01/22 11:07:54 d2.engine.train_loop]: \u001b[0mException during training:\n",
      "Traceback (most recent call last):\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py\", line 149, in train\n",
      "    self.run_step()\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py\", line 497, in run_step\n",
      "    self._trainer.run_step()\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py\", line 273, in run_step\n",
      "    loss_dict = self.model(data)\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py\", line 154, in forward\n",
      "    features = self.backbone(images.tensor)\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py\", line 126, in forward\n",
      "    bottom_up_features = self.bottom_up(x)\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py\", line 449, in forward\n",
      "    x = stage(x)\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py\", line 195, in forward\n",
      "    out = self.conv1(x)\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/u/yockelle/.local/lib/python3.8/site-packages/detectron2/layers/wrappers.py\", line 84, in forward\n",
      "    x = F.conv2d(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 1.32 GiB (GPU 0; 23.70 GiB total capacity; 20.42 GiB already allocated; 321.69 MiB free; 21.76 GiB reserved in total by PyTorch)\n",
      "\u001b[32m[01/22 11:07:54 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:02 (0:00:00 on hooks)\n",
      "\u001b[32m[01/22 11:07:54 d2.utils.events]: \u001b[0m iter: 0    lr: N/A  max_mem: 22256M\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.32 GiB (GPU 0; 23.70 GiB total capacity; 20.42 GiB already allocated; 321.69 MiB free; 21.76 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cde61180894d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCocoTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \"\"\"\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPECTED_RESULTS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             assert hasattr(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# self.iter == max_iter can be used by `after_train` to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdo\u001b[0m \u001b[0msomething\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \"\"\"\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mgt_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproposal_generator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0;34m\"p2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"p3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"p6\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \"\"\"\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mbottom_up_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottom_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mprev_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlateral_convs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottom_up_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stem\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_out_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/detectron2/layers/wrappers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 ), \"SyncBatchNorm does not support empty inputs!\"\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         x = F.conv2d(\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.32 GiB (GPU 0; 23.70 GiB total capacity; 20.42 GiB already allocated; 321.69 MiB free; 21.76 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/data/rali5/Tmp/yockelle/TableBank/TableBank/output/latex/X152/config_latex_X152.yaml\")\n",
    "cfg.DATASETS.TRAIN = (train_set_name,)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"/data/rali5/Tmp/yockelle/TableBank/TableBank/output/latex/X152/model_final_latex_X152.pth\")\n",
    "#cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "#cfg.SOLVER.BASE_LR = 0.0125  # pick a good LR\n",
    "#cfg.SOLVER.BASE_LR = 0.0125  # pick a good LR\n",
    "#cfg.SOLVER.MAX_ITER = 3000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "#cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "#cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "#cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\n",
    "#cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = 0.5\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.TEST.EVAL_PERIOD = 1000\n",
    "CUDA_LAUNCH_BLOCKING = 1\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "#trainer = DefaultTrainer(cfg) \n",
    "trainer = CocoTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (test_set_name, )\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\"\"\"\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/data/rali5/Tmp/yockelle/TableBank/TableBank/output/latex/X152/config_latex_X152.yaml\")\n",
    "cfg.DATASETS.TRAIN = (train_set_name,)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"/data/rali5/Tmp/yockelle/TableBank/TableBank/output/latex/X152/model_final_latex_X152.pth\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "#cfg.SOLVER.BASE_LR = 0.0125  # pick a good LR\n",
    "#cfg.SOLVER.MAX_ITER = 7000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "#cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "#cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\n",
    "cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = 0.5\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.TEST.EVAL_PERIOD = 1000\n",
    "CUDA_LAUNCH_BLOCKING = 1\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "Precision  0.9611628518892508\n",
      "Recall  0.8376718111558195\n",
      "F1  0.895178465812773\n"
     ]
    }
   ],
   "source": [
    "test_data = get_test_data_word()\n",
    "threshold = 0.975\n",
    "\n",
    "precision_tab = []\n",
    "recall_tab = []\n",
    "\n",
    "sum_numerator = 0\n",
    "sum_numerator_old = 0\n",
    "sum_denominator_precision = 0\n",
    "sum_denominator_recall = 0\n",
    "\n",
    "test_count = 0\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "  if i%1000 == 0:\n",
    "    print(i)\n",
    "  image_dict = test_data[i]\n",
    "  image_name = \"/data/rali5/Tmp/yockelle/TableBank/\" + image_dict[\"file_name\"]\n",
    "  im = cv2.imread(image_name)\n",
    "  outputs = predictor(im)\n",
    "\n",
    "  predictions_detectron = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
    "  scores_detectron = outputs[\"instances\"].scores.cpu().numpy()\n",
    "  predictions_with_threshold = []\n",
    "  for j, p in enumerate(predictions_detectron):\n",
    "    if scores_detectron[j]>threshold:\n",
    "      predictions_with_threshold.append(p)\n",
    "  predictions_with_threshold = np.array(predictions_with_threshold)\n",
    "\n",
    "  # Get the ground truth\n",
    "  bbox_ground_truth = []\n",
    "  truth = image_dict[\"annotations\"]\n",
    "  for t in truth:\n",
    "      x_min = t[\"bbox\"][0]\n",
    "      y_min = t[\"bbox\"][1]\n",
    "      w = t[\"bbox\"][2]\n",
    "      h = t[\"bbox\"][3]\n",
    "      x_max = x_min + w\n",
    "      y_max = y_min + h\n",
    "      bbox_ground_truth.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "  result = metric_table_bank_union(bbox_ground_truth, predictions_with_threshold)\n",
    "\n",
    "  if result != None:\n",
    "    test_count += 1\n",
    "    numerator, denominator_precision, denominator_recall, old_way_area_union = result\n",
    "\n",
    "    sum_numerator += numerator\n",
    "    sum_numerator_old += old_way_area_union\n",
    "    sum_denominator_precision += denominator_precision\n",
    "    sum_denominator_recall += denominator_recall\n",
    "\n",
    "precision = sum_numerator/sum_denominator_precision\n",
    "recall = sum_numerator/sum_denominator_recall\n",
    "f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Precision \", precision)\n",
    "print(\"Recall \", recall)\n",
    "print(\"F1 \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68ca6d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "First\n",
      "Precision  0.8011931394705466\n",
      "Recall  0.9880021048699609\n",
      "F1  0.8848453076411419\n"
     ]
    }
   ],
   "source": [
    "test_latex_predictions = {}\n",
    "test_latex_truth = {}\n",
    "\n",
    "test_data = get_test_data_both() + get_test_data_publaynet()\n",
    "\n",
    "count_pred = 0\n",
    "count_truth = 0\n",
    "\n",
    "all_image_preds = []\n",
    "all_annotations_preds = []\n",
    "\n",
    "all_image_truth = []\n",
    "all_annotations_truth = []\n",
    "\n",
    "sum_numerator = 0\n",
    "sum_numerator_old = 0\n",
    "sum_denominator_precision = 0\n",
    "sum_denominator_recall = 0\n",
    "\n",
    "for index, image_dict in enumerate(test_data):\n",
    "  one_image_pred = {}\n",
    "  one_image_truth = {}\n",
    "  \n",
    "  if index%500 == 0:\n",
    "    print(index)\n",
    "\n",
    "  try: \n",
    "    image_name = \"/data/rali5/Tmp/yockelle/TableBank/\" + image_dict[\"file_name\"]  \n",
    "    im = cv2.imread(image_name).shape\n",
    "  except:\n",
    "    image_name = image_dict[\"file_name\"]\n",
    "    im = cv2.imread(image_name).shape\n",
    "  #image_name = \"/data/rali5/Tmp/yockelle/PubLayNet/\" + image_dict[\"file_name\"]\n",
    "  #image_name = image_dict[\"file_name\"]\n",
    "  only_name = image_dict[\"file_name\"].split(\"/\")[-1]\n",
    "\n",
    "  truths_boxes = []\n",
    "  preds_boxes = []\n",
    "\n",
    "  problem = False\n",
    "\n",
    "  # ADD TRUTH\n",
    "  for annot in image_dict[\"annotations\"]:\n",
    "    #if scores_detectron[j]>threshold:\n",
    "    p = annot[\"bbox\"]\n",
    "    x1 = p[0]\n",
    "    y1 = p[1]\n",
    "    w = p[2]\n",
    "    h = p[3]\n",
    "    x2 = p[0] + w\n",
    "    y2 = p[1] + h\n",
    "    if y1 == y2 or y2<y1:\n",
    "      #print(\"here\")\n",
    "      #print(count_truth)\n",
    "      problem = True\n",
    "      break\n",
    "\n",
    "    if not(problem):\n",
    "      \n",
    "      one_annotations = {}\n",
    "      one_annotations[\"id\"] = count_truth\n",
    "      one_annotations[\"segmentation\"] = []\n",
    "      one_annotations[\"area\"] = float(w * h)\n",
    "      one_annotations[\"iscrowd\"] = 0\n",
    "      one_annotations[\"ignore\"] = 0\n",
    "      one_annotations[\"image_id\"] = index\n",
    "      one_annotations[\"bbox\"] = [float(pp) for pp in p]\n",
    "      one_annotations[\"category_id\"] = 0\n",
    "\n",
    "      all_annotations_truth.append(one_annotations)\n",
    "      count_truth += 1\n",
    "\n",
    "      truths_boxes.append([x1,y1,x2,y2])\n",
    "\n",
    "  if problem:\n",
    "    continue\n",
    "\n",
    "  if problem:\n",
    "    print(\"wtf\")\n",
    "\n",
    "  one_image_truth[\"id\"] = index\n",
    "  one_image_truth[\"file_name\"] = only_name\n",
    "  one_image_truth[\"width\"] = image_dict[\"width\"]\n",
    "  one_image_truth[\"height\"] = image_dict[\"height\"]\n",
    "\n",
    "  all_image_truth.append(one_image_truth)\n",
    "  \n",
    "\n",
    "  # ADD PREDS\n",
    "  im = cv2.imread(image_name)\n",
    "  outputs = predictor(im)\n",
    "  predictions_detectron = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
    "  scores_detectron = outputs[\"instances\"].scores.cpu().numpy()\n",
    "\n",
    "  for j, p in enumerate(predictions_detectron):\n",
    "    #if scores_detectron[j]>threshold:\n",
    "    x1 = p[0]\n",
    "    y1 = p[1]\n",
    "    x2 = p[2]\n",
    "    y2 = p[3]\n",
    "    w = x2-x1\n",
    "    h = y2-y1\n",
    "    #x2 = p[0] + w\n",
    "    #y2 = p[1] + h\n",
    "    \n",
    "    one_annotations = {}\n",
    "    one_annotations[\"id\"] = count_pred\n",
    "    one_annotations[\"segmentation\"] = []\n",
    "    one_annotations[\"area\"] = float(w * h)\n",
    "    one_annotations[\"iscrowd\"] = 0\n",
    "    one_annotations[\"ignore\"] = 0\n",
    "    one_annotations[\"image_id\"] = index\n",
    "    one_annotations[\"bbox\"] = [float(pp) for pp in [x1,y1,w,h]]\n",
    "    one_annotations[\"category_id\"] = 0\n",
    "    one_annotations[\"score\"] = float(scores_detectron[j])\n",
    "\n",
    "    all_annotations_preds.append(one_annotations)\n",
    "    count_pred += 1\n",
    "\n",
    "    preds_boxes.append([x1,y1,x2,y2])\n",
    "\n",
    "  one_image_pred[\"id\"] = index\n",
    "  one_image_pred[\"file_name\"] = only_name\n",
    "  one_image_pred[\"width\"] = image_dict[\"width\"]\n",
    "  one_image_pred[\"height\"] = image_dict[\"height\"]\n",
    "\n",
    "  all_image_preds.append(one_image_pred)\n",
    "\n",
    "  result = metric_table_bank_union(np.array(truths_boxes), np.array(preds_boxes))\n",
    "  numerator, denominator_precision, denominator_recall, old_way_area_union = result\n",
    "\n",
    "  sum_numerator += numerator\n",
    "  sum_numerator_old += old_way_area_union\n",
    "  sum_denominator_precision += denominator_precision\n",
    "  sum_denominator_recall += denominator_recall\n",
    "\n",
    "\n",
    "# ADD TRUTHS\n",
    "test_latex_truth[\"images\"] = all_image_truth\n",
    "test_latex_truth[\"annotations\"] = all_annotations_truth\n",
    "test_latex_truth[\"categories\"] = [{\"id\": 0, \"name\": \"table\", \"supercategory\": \"none\"}]\n",
    "\n",
    "test_type = \"word-latex-publaynet\"\n",
    "train_type = \"latex\"\n",
    "\n",
    "path_truth = \"prediction_and_truth_models/train_\"+train_type+\"/annotations_test_\"+test_type+\"/truth\"\n",
    "if not path.exists(path_truth):\n",
    "  os.makedirs(path_truth)\n",
    "out_file = open(path_truth + \"/test_\"+test_type+\"_truth.json\", \"w\")\n",
    "json.dump(test_latex_truth, out_file, indent = 6)\n",
    "out_file.close()\n",
    "  \n",
    "# ADD PREDS\n",
    "test_latex_predictions[\"images\"] = all_image_preds\n",
    "test_latex_predictions[\"annotations\"] = all_annotations_preds\n",
    "test_latex_predictions[\"categories\"] = [{\"id\": 0, \"name\": \"table\", \"supercategory\": \"none\"}]\n",
    "\n",
    "path_pred = \"prediction_and_truth_models/train_\"+train_type+\"/annotations_test_\"+test_type+\"/preds\"\n",
    "if not path.exists(path_pred):\n",
    "  os.makedirs(path_pred)\n",
    "out_file = open(path_pred + \"/test_\"+test_type+\"_preds.json\", \"w\")\n",
    "json.dump(test_latex_predictions, out_file, indent = 6)\n",
    "out_file.close()\n",
    "\n",
    "precision = sum_numerator/sum_denominator_precision\n",
    "recall = sum_numerator/sum_denominator_recall\n",
    "f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"First\")\n",
    "print(\"Precision \", precision)\n",
    "print(\"Recall \", recall)\n",
    "print(\"F1 \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Precision-Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/yockelle/.local/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/u/yockelle/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "precision  0.972882911193473\n",
      "recall  0.8826494957488177\n",
      "f1  0.92557220534092\n",
      "0.98\n",
      "0\n",
      "4000\n",
      "precision  0.9743411233985767\n",
      "recall  0.8630515724902792\n",
      "f1  0.9153259840126777\n",
      "0.985\n",
      "0\n",
      "4000\n",
      "precision  0.9786959817391115\n",
      "recall  0.8351469028012577\n",
      "f1  0.9012411437615495\n"
     ]
    }
   ],
   "source": [
    "test_data = get_test_data_both()\n",
    "#threshold_pred = [0.0, 0.6, 0.8, 0.95, 0.97, 0.99]\n",
    "\n",
    "threshold_pred = [0.975, 0.98, 0.985]\n",
    "\n",
    "recall_with_threshold = []\n",
    "precision_with_threshold = []\n",
    "\n",
    "for threshold_ind, threshold in enumerate(threshold_pred):\n",
    "  print(threshold)\n",
    "\n",
    "  precision_tab = []\n",
    "  recall_tab = []\n",
    "\n",
    "  sum_numerator = 0\n",
    "  sum_numerator_old = 0\n",
    "  sum_denominator_precision = 0\n",
    "  sum_denominator_recall = 0\n",
    "\n",
    "  test_count = 0\n",
    "\n",
    "  for i in range(len(test_data)):\n",
    "    if i%4000 == 0:\n",
    "      print(i)\n",
    "    image_dict = test_data[i]\n",
    "    image_name = \"/data/rali5/Tmp/yockelle/TableBank/\" + image_dict[\"file_name\"]\n",
    "    im = cv2.imread(image_name)\n",
    "    outputs = predictor(im)\n",
    "\n",
    "    predictions_detectron = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
    "    scores_detectron = outputs[\"instances\"].scores.cpu().numpy()\n",
    "    predictions_with_threshold = []\n",
    "    for j, p in enumerate(predictions_detectron):\n",
    "      if scores_detectron[j]>threshold:\n",
    "        predictions_with_threshold.append(p)\n",
    "    predictions_with_threshold = np.array(predictions_with_threshold)\n",
    "\n",
    "    # Get the ground truth\n",
    "    bbox_ground_truth = []\n",
    "    truth = image_dict[\"annotations\"]\n",
    "    for t in truth:\n",
    "        x_min = t[\"bbox\"][0]\n",
    "        y_min = t[\"bbox\"][1]\n",
    "        w = t[\"bbox\"][2]\n",
    "        h = t[\"bbox\"][3]\n",
    "        x_max = x_min + w\n",
    "        y_max = y_min + h\n",
    "        bbox_ground_truth.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "    result = metric_table_bank_union(bbox_ground_truth, predictions_with_threshold)\n",
    "\n",
    "    if result != None:\n",
    "      test_count += 1\n",
    "      numerator, denominator_precision, denominator_recall, old_way_area_union = result\n",
    "\n",
    "      #precision_tab.append(precision)\n",
    "      #recall_tab.append(recall)\n",
    "\n",
    "      sum_numerator += numerator\n",
    "      sum_numerator_old += old_way_area_union\n",
    "      sum_denominator_precision += denominator_precision\n",
    "      sum_denominator_recall += denominator_recall\n",
    "\n",
    "  precision = sum_numerator/sum_denominator_precision\n",
    "  recall = sum_numerator/sum_denominator_recall\n",
    "  f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "  precision_with_threshold.append(precision)\n",
    "  recall_with_threshold.append(recall)\n",
    "\n",
    "  #precision_old = sum_numerator_old/sum_denominator_precision\n",
    "  #recall_old = sum_numerator_old/sum_denominator_recall\n",
    "  #f1_old = (2 * precision_old * recall_old) / (precision_old + recall_old)\n",
    "\n",
    "  print(\"precision \", precision)\n",
    "  print(\"recall \", recall)\n",
    "  print(\"f1 \", f1)\n",
    "\n",
    "with open('X101model_recall_with_threshold_latex-word_0.975_0.98_0.985.pkl', 'wb') as f:\n",
    "  pickle.dump(recall_with_threshold, f)\n",
    "\n",
    "with open('X101model_precision_with_threshold_latex-word_0.975_0.98_0.985.pkl', 'wb') as f:\n",
    "    pickle.dump(precision_with_threshold, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('image_curve/v2_recall_with_threshold_latex-word.pkl', 'rb') as f:\n",
    "    recall_with_threshold = pickle.load(f)\n",
    "\n",
    "with open('image_curve/v2_precision_with_threshold_latex-word.pkl', 'rb') as f:\n",
    "    precision_with_threshold = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904122891197051\n"
     ]
    }
   ],
   "source": [
    "recall = recall_with_threshold[6]\n",
    "precision = precision_with_threshold[6]\n",
    "\n",
    "print((2 * precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 936x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('image_curve/X101model_recall_with_threshold_latex-word.pkl', 'rb') as f:\n",
    "    recall_with_threshold = pickle.load(f)\n",
    "\n",
    "with open('image_curve/X101model_precision_with_threshold_latex-word.pkl', 'rb') as f:\n",
    "    precision_with_threshold = pickle.load(f)\n",
    "\n",
    "threshold_pred = [0.0, 0.6, 0.8, 0.95, 0.97, 0.975, 0.98, 0.985, 0.99]\n",
    "\n",
    "plt.figure(figsize=(13, 9))\n",
    "\n",
    "plt.rcParams['text.usetex']=True\n",
    "plt.rc({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"]})\n",
    "\n",
    "colors_choices = [\"#f81aa1\", \"#3cc84b\", \"#6a2020\", \"#ff8d00\", \"#ff0000\", \"#bc21e9\", \"#1798e7\", \"#09701d\", \"#2af0f0\"]\n",
    "\n",
    "plt.plot(recall_with_threshold, precision_with_threshold, '--', color=\"k\")\n",
    "\n",
    "for thresh_ind, threshold in enumerate(threshold_pred):\n",
    "  plt.plot(recall_with_threshold[thresh_ind], precision_with_threshold[thresh_ind], 'o', markersize=10, color=colors_choices[thresh_ind], label=threshold)\n",
    "\n",
    "plt.plot(0.8817, 0.9670, 'o', markersize=10, color=\"k\", label=\"paper\")\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Recall', fontsize=15)\n",
    "plt.ylabel('Precision', fontsize=15)\n",
    "plt.xticks(fontsize = 17)\n",
    "plt.yticks(fontsize = 17)\n",
    "#plt.xlim(min(recall_with_threshold)-0.009, 1.0)\n",
    "#plt.ylim(min(precision_with_threshold)-0.02, 1.0)\n",
    "plt.legend(prop={'size': 14}, title=\"Prediction threshold\", title_fontsize=14)\n",
    "plt.savefig(\"X101model-precision_latex-word.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/yockelle/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c54c626c85a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0msum_denominator_recall\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdenominator_recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_numerator\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum_denominator_precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_numerator\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum_denominator_recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "test_data = get_test_data_both()\n",
    "\n",
    "precision_tab = []\n",
    "recall_tab = []\n",
    "\n",
    "sum_numerator = 0\n",
    "sum_denominator_precision = 0\n",
    "sum_denominator_recall = 0\n",
    "\n",
    "test_count = 0\n",
    "\n",
    "for i in  range(len(test_data)):\n",
    "  if not i%100:\n",
    "    print(i)\n",
    "\n",
    "  image_dict = test_data[i]\n",
    "  image_name = \"/data/rali5/Tmp/yockelle/TableBank/\" + image_dict[\"file_name\"]\n",
    "  im = cv2.imread(image_name)\n",
    "  outputs = predictor(im)\n",
    "\n",
    "  predictions_detectron = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
    "\n",
    "  # Get the ground truth\n",
    "  bbox_ground_truth = []\n",
    "  truth = image_dict[\"annotations\"]\n",
    "  for t in truth:\n",
    "      x_min = t[\"bbox\"][0]\n",
    "      y_min = t[\"bbox\"][1]\n",
    "      w = t[\"bbox\"][2]\n",
    "      h = t[\"bbox\"][3]\n",
    "      x_max = x_min + w\n",
    "      y_max = y_min + h\n",
    "      bbox_ground_truth.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "  result = measure_metric_table_bank(bbox_ground_truth, predictions_detectron)\n",
    "\n",
    "  if result != None:\n",
    "    test_count += 1\n",
    "    precision, recall, numerator, denominator_precision, denominator_recall = result\n",
    "\n",
    "    #precision_tab.append(precision)\n",
    "    #recall_tab.append(recall)\n",
    "\n",
    "    sum_numerator += numerator\n",
    "    sum_denominator_precision += denominator_precision\n",
    "    sum_denominator_recall += denominator_recall\n",
    "\n",
    "precision = sum_numerator/sum_denominator_precision\n",
    "recall = sum_numerator/sum_denominator_recall\n",
    "f1 = (2 * precision * recall) / (precision + recall)\n",
    "print(sum_numerator)\n",
    "print(sum_denominator_precision)\n",
    "print(sum_denominator_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old way with only intersect\n",
      "precision  0.7458786797677166\n",
      "recall  0.9658888741440649\n",
      "f1  0.841745033199794\n"
     ]
    }
   ],
   "source": [
    "print(\"Old way with only intersect\")\n",
    "print(\"precision \", precision)\n",
    "print(\"recall \", recall)\n",
    "print(\"f1 \", f1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "608c06b448c1de9fbfe61db40b999c2492eeda40b619a01541314540d82445de"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
